{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from tensorflow.keras.models import load_model\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import Orthogonal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\perez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\perez\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "def custom_lstm(**kwargs):\n",
    "    kwargs.pop('time_major', None)\n",
    "    return tf.keras.layers.LSTM(**kwargs)\n",
    "\n",
    "model = load_model('modelo_lstmMeans.h5', custom_objects={'Orthogonal': Orthogonal, 'LSTM': custom_lstm})\n",
    "w2v_model = Word2Vec.load(\"word2vecSentiments.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\perez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\perez\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.20.10.13:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:172.20.10.11 - - [26/Jun/2024 13:39:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from tensorflow.keras.models import load_model\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import Orthogonal\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "def custom_lstm(**kwargs):\n",
    "    kwargs.pop('time_major', None)\n",
    "    return tf.keras.layers.LSTM(**kwargs)\n",
    "\n",
    "model = load_model('modelo_lstmMeans.h5', custom_objects={'Orthogonal': Orthogonal, 'LSTM': custom_lstm})\n",
    "w2v_model = Word2Vec.load(\"word2vecSentiments.model\")\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    words_filtered = [e.lower() for e in texto.split() if len(e) >= 3]\n",
    "    words_cleaned = [word for word in words_filtered if 'http' not in word and not word.startswith('@') and not word.startswith('#') and word != 'rt']\n",
    "    words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]\n",
    "    words_final = [re.sub(r'[^a-zA-Z]', '', word) for word in words_without_stopwords]\n",
    "    return words_final\n",
    "\n",
    "def media_embedding(opinion):\n",
    "    embeddings = [w2v_model.wv[palabra] for palabra in opinion if palabra in w2v_model.wv.key_to_index]\n",
    "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(w2v_model.vector_size)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    array_strings = data.get('array_strings')\n",
    "\n",
    "    if not array_strings:\n",
    "        return jsonify({'error': 'No se proporcionaron frases para predecir.'}), 400\n",
    "\n",
    "    predicciones = []\n",
    "    for frase in array_strings:\n",
    "        frase_limpia = limpiar_texto(frase)\n",
    "        embedding = media_embedding(frase_limpia)\n",
    "\n",
    "        # Redimensionar el embedding para que sea compatible con el modelo\n",
    "        embedding = np.expand_dims(embedding, axis=0)  # Añadir dimensión batch\n",
    "        embedding = np.expand_dims(embedding, axis=1)  # Añadir dimensión timesteps\n",
    "\n",
    "        # Predecir la etiqueta\n",
    "        prediccion = model.predict(embedding)\n",
    "\n",
    "        # Convertir la predicción a etiqueta\n",
    "        etiqueta = np.argmax(prediccion, axis=1)[0]\n",
    "        predicciones.append(etiqueta)\n",
    "\n",
    "    # Determinar la predicción más frecuente\n",
    "    prediccionReal = Counter(predicciones).most_common(1)[0][0]\n",
    "\n",
    "    return jsonify({'prediccionReal': int(prediccionReal)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
